{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert xlsx -> json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_one\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# .xlsx íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = os.path.join(os.getcwd(),\"data\",\"1_one\", \"Number_factor_AO_sub-corpus.xlsx\")\n",
    "json_file_path = os.path.join(os.getcwd(), \"preprocessing\", \"1_one\", \"Number_factor_AO_sub-corpus.json\")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# í•„ìš”í•œ ì—´ë§Œ ì„ íƒ (1, 2, 3, 7, 10, 13, 14)\n",
    "df_selected = df.iloc[:, [0, 1, 2, 6, 9, 12, 13]]  # Pandasì˜ ilocì„ ì‚¬ìš©í•˜ì—¬ ì—´ ì„ íƒ\n",
    "\n",
    "# ì—´ ì´ë¦„ì„ ì ì ˆí•œ JSON í‚¤ë¡œ ë§¤í•‘\n",
    "df_selected.columns = [\"text_id\", \"text\", \"anaphor\", \"A\", \"B\", \"A_coref\", \"B_coref\"]\n",
    "\n",
    "# JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "data_list = []\n",
    "for index, row in df_selected.iterrows():\n",
    "    # A_corefì™€ B_corefê°€ ëª¨ë‘ Falseì¸ ê²½ìš° \"Neither\" ì €ì¥\n",
    "    if row[\"A_coref\"] == False and row[\"B_coref\"] == False:\n",
    "        answer = \"Neither\"\n",
    "    elif row[\"A_coref\"] == True:\n",
    "        answer = \"A\"\n",
    "    else:\n",
    "        answer = \"B\"\n",
    "\n",
    "    data_list.append({\n",
    "        \"text_id\": row[\"text_id\"],  # ë¬¸ì¥ ID\n",
    "        \"text\": row[\"text\"],  # ì „ì²´ ë¬¸ì¥\n",
    "        \"anaphor\": row[\"anaphor\"],  # anaphoric one/ones\n",
    "        \"options\": {\n",
    "            \"A\": row[\"A\"],  # ì„ í–‰ì‚¬ í›„ë³´ A\n",
    "            \"B\": row[\"B\"]   # ì„ í–‰ì‚¬ í›„ë³´ B\n",
    "        },\n",
    "        \"answer\": answer  # \"A\", \"B\", \"Neither\" ì¤‘ í•˜ë‚˜\n",
    "    })\n",
    "\n",
    "# JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data_list, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… JSON ë³€í™˜ ì™„ë£Œ: {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_npe\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# .xlsx íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = os.path.join(os.getcwd(),\"data\",\"2_npe\", \"General_NPE_corpus.xlsx\")\n",
    "json_file_path = os.path.join(os.getcwd(),\"preprocessing\",\"2_npe\", \"General_NPE_corpus.json\")\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# í•„ìš”í•œ ì—´ë§Œ ì„ íƒ (1, 2, 3, 7, 10, 13, 14)\n",
    "df_selected = df.iloc[:, [0, 1, 2, 5, 8, 11, 12]]  # Pandasì˜ ilocì„ ì‚¬ìš©í•˜ì—¬ ì—´ ì„ íƒ\n",
    "\n",
    "# ì—´ ì´ë¦„ì„ ì ì ˆí•œ JSON í‚¤ë¡œ ë§¤í•‘\n",
    "df_selected.columns = [\"text_id\", \"text\", \"licensor\", \"A\", \"B\", \"A_coref\",\"B_coref\"]\n",
    "\n",
    "# JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "data_list = []\n",
    "for index, row in df_selected.iterrows():\n",
    "    # A_corefì™€ B_corefê°€ ëª¨ë‘ Falseì¸ ê²½ìš° \"Neither\" ì €ì¥\n",
    "    if row[\"A_coref\"] == False and row[\"B_coref\"] == False:\n",
    "        answer = \"Neither\"\n",
    "    elif row[\"A_coref\"] == True:\n",
    "        answer = \"A\"\n",
    "    else:\n",
    "        answer = \"B\"\n",
    "\n",
    "    data_list.append({\n",
    "        \"text_id\": row[\"text_id\"],  # ë¬¸ì¥ ID\n",
    "        \"text\": row[\"text\"],  # ì „ì²´ ë¬¸ì¥\n",
    "        \"licensor\": row[\"licensor\"],  # licensor\n",
    "        \"options\": {\n",
    "            \"A\": row[\"A\"],  # ì„ í–‰ì‚¬ í›„ë³´ A\n",
    "            \"B\": row[\"B\"]   # ì„ í–‰ì‚¬ í›„ë³´ B\n",
    "        },\n",
    "        \"answer\": answer  # \"A\", \"B\", \"Neither\" ì¤‘ í•˜ë‚˜\n",
    "    })\n",
    "\n",
    "\n",
    "# JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data_list, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… JSON ë³€í™˜ ì™„ë£Œ: {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .tsv->json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# .tsv íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = os.path.join(os.getcwd(), \"data\", \"gap\", \"gap-development.tsv\")\n",
    "json_file_path = os.path.join(os.getcwd(), \"preprocessing\", \"gap\", \"gap-development.json\")\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)  # Tab-separated values (TSV)\n",
    "\n",
    "# í•„ìš”í•œ ì—´ë§Œ ì„ íƒ (ID, Text, Pronoun, A, A-coref, B, B-coref)\n",
    "df_selected = df[[\"ID\", \"Text\", \"Pronoun\", \"A\", \"A-coref\", \"B\", \"B-coref\"]]\n",
    "\n",
    "# JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "data_list = []\n",
    "for index, row in df_selected.iterrows():\n",
    "    # A-corefì™€ B-corefê°€ ëª¨ë‘ Falseì¸ ê²½ìš° \"Neither\" ì €ì¥\n",
    "    if row[\"A-coref\"] == \"FALSE\" and row[\"B-coref\"] == \"FALSE\":\n",
    "        answer = \"Neither\"\n",
    "    elif row[\"A-coref\"] == \"TRUE\":\n",
    "        answer = \"A\"\n",
    "    else:\n",
    "        answer = \"B\"\n",
    "\n",
    "    data_list.append({\n",
    "        \"text_id\": row[\"ID\"],  # ë¬¸ì¥ ID\n",
    "        \"text\": row[\"Text\"],  # ì „ì²´ ë¬¸ì¥\n",
    "        \"pronoun\": row[\"Pronoun\"],  # ëŒ€ëª…ì‚¬\n",
    "        \"options\": {\n",
    "            \"A\": row[\"A\"],  # ì„ í–‰ì‚¬ í›„ë³´ A\n",
    "            \"B\": row[\"B\"]   # ì„ í–‰ì‚¬ í›„ë³´ B\n",
    "        },\n",
    "        \"answer\": answer  # \"A\", \"B\", \"Neither\" ì¤‘ í•˜ë‚˜\n",
    "    })\n",
    "\n",
    "# JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data_list, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… JSON ë³€í™˜ ì™„ë£Œ: {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# .tsv íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = os.path.join(os.getcwd(),\"data\",\"gap\", \"gap-test.tsv\")\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", dtype=str)  # Tab-separated values (TSV)\n",
    "\n",
    "# A-corefì™€ B-corefê°€ ëª¨ë‘ Falseì¸ í–‰ í•„í„°ë§\n",
    "false_coref_rows = df[(df[\"A-coref\"] == \"FALSE\") & (df[\"B-coref\"] == \"FALSE\")]\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "if not false_coref_rows.empty:\n",
    "    print(\"ğŸ” A-corefì™€ B-corefê°€ ëª¨ë‘ Falseì¸ í–‰ì´ ì¡´ì¬í•©ë‹ˆë‹¤:\")\n",
    "    print(false_coref_rows)\n",
    "else:\n",
    "    print(\"âœ… ëª¨ë“  í–‰ì—ì„œ ìµœì†Œ í•˜ë‚˜ì˜ coref ê°’ì´ Trueì…ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON â†’ Fine-tuningìš© JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ: /jsm0707/LLM_Anaphoric-One-and-NPE/preprocessing/new/train/gap-dev_npe_sft.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "name=\"gap-dev_npe\"\n",
    "input_json_path=os.path.join(os.getcwd(), \"preprocessing\", \"new\", \"train\", f\"{name}.json\")\n",
    "output_jsonl_path=os.path.join(os.getcwd(), \"preprocessing\", \"new\", \"train\", f\"{name}_sft.jsonl\")\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# SFT í¬ë§· ë³€í™˜ (promptì™€ outputì„ í•˜ë‚˜ì˜ textë¡œ í•©ì³ ì €ì¥)\n",
    "with open(output_jsonl_path, 'w', encoding='utf-8') as f_out:\n",
    "    for item in data:\n",
    "        # í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°\n",
    "        prompt = f'''Question: In the sentence \"{item[\"text\"]}\", what does \"{item[\"target\"]}\" refer to?\n",
    "Options:\n",
    "(A) {item[\"options\"][\"A\"]}\n",
    "(B) {item[\"options\"][\"B\"]}\n",
    "Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none are correct.\n",
    "Answer:'''\n",
    "        output = item[\"answer\"].strip().upper()  # ì •ë‹µ (A, B, Neither)\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ì™€ ì •ë‹µì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°\n",
    "        combined_text = prompt.strip() + \" \" + output\n",
    "        \n",
    "        # JSONLë¡œ ì €ì¥\n",
    "        json.dump({\"text\": combined_text}, f_out, ensure_ascii=False)\n",
    "        f_out.write('\\n')  # jsonl í˜•ì‹\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {output_jsonl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "name=\"Number_factor_AO_sub-corpus\"\n",
    "input_json_path=os.path.join(os.getcwd(), \"preprocessing\", \"1_one\", f\"{name}.json\")\n",
    "output_jsonl_path=os.path.join(os.getcwd(), \"preprocessing\", \"1_one\", f\"{name}_sft.jsonl\")\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# SFT í¬ë§· ë³€í™˜ (promptì™€ outputì„ í•˜ë‚˜ì˜ textë¡œ í•©ì³ ì €ì¥)\n",
    "with open(output_jsonl_path, 'w', encoding='utf-8') as f_out:\n",
    "    for item in data:\n",
    "        # í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°\n",
    "        prompt = f'''Question: In the sentence \"{item[\"text\"]}\", what does \"{item[\"anaphor\"]}\" refer to?\n",
    "Options:\n",
    "(A) {item[\"options\"][\"A\"]}\n",
    "(B) {item[\"options\"][\"B\"]}\n",
    "Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none are correct.\n",
    "Answer:'''\n",
    "        output = item[\"answer\"].strip().upper()  # ì •ë‹µ (A, B, Neither)\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ì™€ ì •ë‹µì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°\n",
    "        combined_text = prompt.strip() + \" \" + output\n",
    "        \n",
    "        # JSONLë¡œ ì €ì¥\n",
    "        json.dump({\"text\": combined_text}, f_out, ensure_ascii=False)\n",
    "        f_out.write('\\n')  # jsonl í˜•ì‹\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {output_jsonl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.npe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "name = \"General_NPE_corpus\"\n",
    "input_json_path=os.path.join(os.getcwd(), \"preprocessing\", \"2_npe\", f\"{name}.json\")\n",
    "output_jsonl_path=os.path.join(os.getcwd(), \"preprocessing\", \"2_npe\", f\"{name}_sft.jsonl\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# SFT í¬ë§· ë³€í™˜ (promptì™€ outputì„ í•˜ë‚˜ì˜ textë¡œ í•©ì³ ì €ì¥)\n",
    "with open(output_jsonl_path, 'w', encoding='utf-8') as f_out:\n",
    "    for item in data:\n",
    "        # í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°\n",
    "        prompt = f'''Question: In the sentence \"{item[\"text\"]}\", what does \"{item[\"licensor\"]}\" refer to?\n",
    "Options:\n",
    "(A) {item[\"options\"][\"A\"]}\n",
    "(B) {item[\"options\"][\"B\"]}\n",
    "Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none are correct.\n",
    "Answer:'''\n",
    "        output = item[\"answer\"].strip().upper()  # ì •ë‹µ (A, B, Neither)\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ì™€ ì •ë‹µì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°\n",
    "        combined_text = prompt.strip() + \" \" + output\n",
    "        \n",
    "        # JSONLë¡œ ì €ì¥\n",
    "        json.dump({\"text\": combined_text}, f_out, ensure_ascii=False)\n",
    "        f_out.write('\\n')  # jsonl í˜•ì‹\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {output_jsonl_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "name = \"gap-test\"\n",
    "input_json_path = os.path.join(os.getcwd(), \"preprocessing\", \"gap\", f\"{name}.json\")\n",
    "output_jsonl_path = os.path.join(os.getcwd(), \"preprocessing\", \"gap\", f\"{name}_sft.jsonl\")  # ìµœì¢… íŒŒì¼ëª…ë„ _readyë¡œ\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# SFT í¬ë§· ë³€í™˜ (promptì™€ outputì„ í•˜ë‚˜ì˜ textë¡œ í•©ì³ ì €ì¥)\n",
    "with open(output_jsonl_path, 'w', encoding='utf-8') as f_out:\n",
    "    for item in data:\n",
    "        # í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°\n",
    "        prompt = f'''Question: In the sentence \"{item[\"text\"]}\", who does \"{item[\"pronoun\"]}\" refer to?\n",
    "Options:\n",
    "(A) {item[\"options\"][\"A\"]}\n",
    "(B) {item[\"options\"][\"B\"]}\n",
    "Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none are correct.\n",
    "Answer:'''\n",
    "        output = item[\"answer\"].strip().upper()  # ì •ë‹µ (A, B, Neither)\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ì™€ ì •ë‹µì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°\n",
    "        combined_text = prompt.strip() + \" \" + output\n",
    "        \n",
    "        # JSONLë¡œ ì €ì¥\n",
    "        json.dump({\"text\": combined_text}, f_out, ensure_ascii=False)\n",
    "        f_out.write('\\n')  # jsonl í˜•ì‹\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {output_jsonl_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSC -> .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³€í™˜ ì™„ë£Œ: /jsm0707/LLM_Anaphoric-One-and-NPE/preprocessing/wsc/wsc.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# ì…ë ¥ .txt íŒŒì¼ê³¼ ì¶œë ¥ .json íŒŒì¼ ê²½ë¡œ\n",
    "input_txt_path = os.path.join(os.getcwd(), \"data\", \"wsc273.txt\")  # WSC ì›ë³¸ .txt ê²½ë¡œ\n",
    "output_json_path = os.path.join(os.getcwd(), \"preprocessing\", \"wsc\", \"wsc.json\")  # ë³€í™˜ëœ .jsonl ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "data = []\n",
    "with open(input_txt_path, 'r', encoding='utf-8') as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]  # ë¹ˆ ì¤„ ì œê±° ë° ì•ë’¤ ê³µë°± ì œê±°\n",
    "\n",
    "# 4ì¤„ì”© í•˜ë‚˜ì˜ ìƒ˜í”Œë¡œ êµ¬ì„±\n",
    "for i in range(0, len(lines), 4):\n",
    "    text = lines[i]  # ë¬¸ì¥\n",
    "    mask = lines[i+1]  # [MASK] (ì‚¬ìš© ì•ˆ í•  ìˆ˜ë„ ìˆì§€ë§Œ í˜•ì‹ìƒ í¬í•¨)\n",
    "    candidates_line = lines[i+2]  # í›„ë³´\n",
    "    answer_line = lines[i+3]  # ì •ë‹µ\n",
    "\n",
    "    # í›„ë³´ ë¶„ë¦¬\n",
    "    candidates = [c.strip() for c in candidates_line.split(\",\")]\n",
    "    assert len(candidates) == 2, f\"í›„ë³´ëŠ” ë°˜ë“œì‹œ 2ê°œì—¬ì•¼ í•©ë‹ˆë‹¤. í™•ì¸ í•„ìš”: {candidates}\"\n",
    "\n",
    "    # ì •ë‹µì´ í›„ë³´ ì¤‘ ì–´ë””ì¸ì§€ ì°¾ì•„ì„œ 'A' ë˜ëŠ” 'B'ë¡œ\n",
    "    if answer_line.strip() == candidates[0]:\n",
    "        answer = \"A\"\n",
    "    elif answer_line.strip() == candidates[1]:\n",
    "        answer = \"B\"\n",
    "    else:\n",
    "        raise ValueError(f\"ì •ë‹µì´ í›„ë³´ì— ì—†ìŠµë‹ˆë‹¤. ì •ë‹µ: {answer_line}, í›„ë³´: {candidates}\")\n",
    "\n",
    "    # í•˜ë‚˜ì˜ ìƒ˜í”Œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "    item = {\n",
    "        \"text_id\": f\"wsc-{i//4 + 1}\",\n",
    "        \"text\": text,\n",
    "        \"MASK\": \"[MASK]\",  # ê³ ì •ê°’\n",
    "        \"options\": {\n",
    "            \"A\": candidates[0],\n",
    "            \"B\": candidates[1]\n",
    "        },\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "    data.append(item)\n",
    "\n",
    "# JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(output_json_path, 'w', encoding='utf-8') as f_out:\n",
    "    json.dump(data, f_out, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPTí˜•ì‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: /jsm0707/LLM_Anaphoric-One-and-NPE/preprocessing/new/train/gap-dev_npe_finetune.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('./preprocessing/new/train/gap-dev_npe.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# GPT í•™ìŠµìš© ë°ì´í„° ì €ì¥ íŒŒì¼\n",
    "output_file = os.path.join(os.getcwd(), \"preprocessing\", \"new\", \"train\",\"gap-dev_npe_finetune.jsonl\")  # ë³€í™˜ëœ .jsonl ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "\n",
    "# JSONL íŒŒì¼ë¡œ ë³€í™˜\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for item in data:\n",
    "        prompt = f'''Question: In the sentence \"{item[\"text\"]}\", what does \"{item[\"target\"]}\" refer to?\n",
    "Options:\n",
    "(A) {item[\"options\"][\"A\"]}\n",
    "(B) {item[\"options\"][\"B\"]}\n",
    "\n",
    "Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none of them are correct. Do not provide explanations.\n",
    "Answer:'''\n",
    "        \n",
    "        # message í¬ë§· êµ¬ì„±\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": item[\"answer\"]}\n",
    "        ]\n",
    "        \n",
    "        # í•œ ì¤„ì— í•˜ë‚˜ì˜ ëŒ€í™”\n",
    "        json.dump({\"messages\": messages}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: /jsm0707/LLM_Anaphoric-One-and-NPE/preprocessing/1_one/General_AO_corpus_finetune.jsonl\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# # ì›ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# with open('./preprocessing/1_one/General_AO_corpus.json', 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # GPT í•™ìŠµìš© ë°ì´í„° ì €ì¥ íŒŒì¼\n",
    "# output_file = os.path.join(os.getcwd(), \"preprocessing\", \"1_one\", \"General_AO_corpus_finetune.jsonl\")  # ë³€í™˜ëœ .jsonl ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "\n",
    "# # JSONL íŒŒì¼ë¡œ ë³€í™˜\n",
    "# with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#     for item in data:\n",
    "#         prompt = f'''Question: In the sentence \"{item[\"text\"]}\", what does \"{item[\"anaphor\"]}\" refer to?\n",
    "# Options:\n",
    "# (A) {item[\"options\"][\"A\"]}\n",
    "# (B) {item[\"options\"][\"B\"]}\n",
    "\n",
    "# Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none of them are correct. Do not provide explanations.\n",
    "# Answer:'''\n",
    "        \n",
    "#         # message í¬ë§· êµ¬ì„±\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#             {\"role\": \"assistant\", \"content\": item[\"answer\"]}\n",
    "#         ]\n",
    "        \n",
    "#         # í•œ ì¤„ì— í•˜ë‚˜ì˜ ëŒ€í™”\n",
    "#         json.dump({\"messages\": messages}, f, ensure_ascii=False)\n",
    "#         f.write(\"\\n\")\n",
    "\n",
    "# print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: {output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### npe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: /jsm0707/LLM_Anaphoric-One-and-NPE/preprocessing/2_npe/General_NPE_corpus.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('./preprocessing/2_npe/General_NPE_corpus.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# GPT í•™ìŠµìš© ë°ì´í„° ì €ì¥ íŒŒì¼\n",
    "output_file = os.path.join(os.getcwd(), \"preprocessing\", \"2_npe\", \"General_NPE_corpus.jsonl\")  # ë³€í™˜ëœ .jsonl ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "\n",
    "# JSONL íŒŒì¼ë¡œ ë³€í™˜\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for item in data:\n",
    "        prompt = f'''Question: In the sentence \"{item[\"text\"]}\", what does \"{item[\"licensor\"]}\" refer to?\n",
    "Options:\n",
    "(A) {item[\"options\"][\"A\"]}\n",
    "(B) {item[\"options\"][\"B\"]}\n",
    "\n",
    "Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none of them are correct. Do not provide explanations.\n",
    "Answer:'''\n",
    "        \n",
    "        # message í¬ë§· êµ¬ì„±\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": item[\"answer\"]}\n",
    "        ]\n",
    "        \n",
    "        # í•œ ì¤„ì— í•˜ë‚˜ì˜ ëŒ€í™”\n",
    "        json.dump({\"messages\": messages}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: /jsm0707/LLM_Anaphoric-One-and-NPE/preprocessing/gap/gap-validation_finetune.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('./preprocessing/gap/gap-validation.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# GPT í•™ìŠµìš© ë°ì´í„° ì €ì¥ íŒŒì¼\n",
    "output_file = os.path.join(os.getcwd(), \"preprocessing\", \"gap\", \"gap-validation_finetune.jsonl\")  # ë³€í™˜ëœ .jsonl ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "\n",
    "# JSONL íŒŒì¼ë¡œ ë³€í™˜\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for item in data:\n",
    "        prompt = f'''Question: In the sentence \"{item[\"text\"]}\", who does \"{item[\"pronoun\"]}\" refer to?\n",
    "Options:\n",
    "(A) {item[\"options\"][\"A\"]}\n",
    "(B) {item[\"options\"][\"B\"]}\n",
    "\n",
    "Answer only with \"A\" if (A) is correct, \"B\" if (B) is correct, or \"Neither\" if none of them are correct. Do not provide explanations.\n",
    "Answer:'''\n",
    "        \n",
    "        # message í¬ë§· êµ¬ì„±\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": item[\"answer\"]}\n",
    "        ]\n",
    "        \n",
    "        # í•œ ì¤„ì— í•˜ë‚˜ì˜ ëŒ€í™”\n",
    "        json.dump({\"messages\": messages}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ. ì €ì¥ ìœ„ì¹˜: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
